{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_job\",\n",
    "    \"state\", \"party\", \"barely_true\", \"false\", \"half_true\", \"mostly_true\",\n",
    "    \"pants_on_fire\", \"context\"\n",
    "]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "train_df = pd.read_csv(\"data/liar/train.tsv\", sep='\\t', header=None, names=cols)\n",
    "valid_df = pd.read_csv(\"data/liar/valid.tsv\", sep='\\t', header=None, names=cols)\n",
    "test_df = pd.read_csv(\"data/liar/test.tsv\", sep='\\t', header=None, names=cols)\n",
    "\n",
    "train_df['clean_statement'] = train_df['statement'].apply(preprocess_text)\n",
    "valid_df['clean_statement'] = valid_df['statement'].apply(preprocess_text)\n",
    "test_df['clean_statement'] = test_df['statement'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Misleading       0.63      0.48      0.54       616\n",
      "    Reliable       0.61      0.73      0.66       668\n",
      "\n",
      "    accuracy                           0.61      1284\n",
      "   macro avg       0.62      0.61      0.60      1284\n",
      "weighted avg       0.62      0.61      0.61      1284\n",
      "\n",
      "Accuracy: 0.6129283489096573\n",
      "\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Misleading       0.56      0.44      0.49       553\n",
      "    Reliable       0.63      0.73      0.68       714\n",
      "\n",
      "    accuracy                           0.61      1267\n",
      "   macro avg       0.60      0.59      0.59      1267\n",
      "weighted avg       0.60      0.61      0.60      1267\n",
      "\n",
      "Accuracy: 0.606156274664562\n"
     ]
    }
   ],
   "source": [
    "def to_binary(label):\n",
    "    reliable = {'true', 'mostly-true', 'half-true'}\n",
    "    return int(label.lower() in reliable)\n",
    "\n",
    "for df in [train_df, valid_df, test_df]:\n",
    "    df['binary_label'] = df['label'].apply(to_binary)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train = tfidf.fit_transform(train_df['clean_statement'])\n",
    "X_valid = tfidf.transform(valid_df['clean_statement'])\n",
    "X_test  = tfidf.transform(test_df['clean_statement'])\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "get_score = lambda text: sia.polarity_scores(text)['compound']\n",
    "\n",
    "train_sent = train_df['clean_statement'].apply(get_score).values.reshape(-1, 1)\n",
    "valid_sent = valid_df['clean_statement'].apply(get_score).values.reshape(-1, 1)\n",
    "test_sent  = test_df['clean_statement'].apply(get_score).values.reshape(-1, 1)\n",
    "\n",
    "X_train = hstack([X_train, train_sent])\n",
    "X_valid = hstack([X_valid, valid_sent])\n",
    "X_test  = hstack([X_test, test_sent])\n",
    "\n",
    "y_train = train_df['binary_label']\n",
    "y_valid = valid_df['binary_label']\n",
    "y_test  = test_df['binary_label']\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "val_preds = model.predict(X_valid)\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "print(\"Validation Results:\")\n",
    "print(classification_report(y_valid, val_preds, target_names=[\"Misleading\", \"Reliable\"]))\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, val_preds))\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(classification_report(y_test, test_preds, target_names=[\"Misleading\", \"Reliable\"]))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, test_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-Clickbait       0.93      0.97      0.95      2345\n",
      "    Clickbait       0.97      0.93      0.95      2455\n",
      "\n",
      "     accuracy                           0.95      4800\n",
      "    macro avg       0.95      0.95      0.95      4800\n",
      " weighted avg       0.95      0.95      0.95      4800\n",
      "\n",
      "Accuracy: 0.9485416666666666\n",
      "\n",
      "Test Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-Clickbait       0.93      0.97      0.95      2396\n",
      "    Clickbait       0.97      0.93      0.95      2404\n",
      "\n",
      "     accuracy                           0.95      4800\n",
      "    macro avg       0.95      0.95      0.95      4800\n",
      " weighted avg       0.95      0.95      0.95      4800\n",
      "\n",
      "Accuracy: 0.9491666666666667\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in string.punctuation]\n",
    "    tokens = [t for t in tokens if t not in stopwords.words('english')]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "data = pd.read_csv(\"data/clickbait/clickbait_data.csv\")\n",
    "data['clean_headline'] = data['headline'].apply(preprocess_text)\n",
    "\n",
    "data['binary_label'] = data['clickbait'].astype(int)\n",
    "\n",
    "train_df, temp_df = train_test_split(data, test_size=0.3, random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train = tfidf.fit_transform(train_df['clean_headline'])\n",
    "X_valid = tfidf.transform(valid_df['clean_headline'])\n",
    "X_test  = tfidf.transform(test_df['clean_headline'])\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "get_score = lambda text: sia.polarity_scores(text)['compound']\n",
    "\n",
    "train_sent = train_df['clean_headline'].apply(get_score).values.reshape(-1, 1)\n",
    "valid_sent = valid_df['clean_headline'].apply(get_score).values.reshape(-1, 1)\n",
    "test_sent  = test_df['clean_headline'].apply(get_score).values.reshape(-1, 1)\n",
    "\n",
    "X_train = hstack([X_train, train_sent])\n",
    "X_valid = hstack([X_valid, valid_sent])\n",
    "X_test  = hstack([X_test, test_sent])\n",
    "\n",
    "y_train = train_df['binary_label']\n",
    "y_valid = valid_df['binary_label']\n",
    "y_test  = test_df['binary_label']\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "val_preds = model.predict(X_valid)\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "print(\"Validation Results:\")\n",
    "print(classification_report(y_valid, val_preds, target_names=[\"Non-Clickbait\", \"Clickbait\"]))\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, val_preds))\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(classification_report(y_test, test_preds, target_names=[\"Non-Clickbait\", \"Clickbait\"]))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, test_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate statements between train and test: 3\n"
     ]
    }
   ],
   "source": [
    "train_statements = set(train_df['clean_headline'])\n",
    "test_statements = set(test_df['clean_headline'])\n",
    "duplicates = train_statements.intersection(test_statements)\n",
    "print(f\"Number of duplicate statements between train and test: {len(duplicates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clickbait\n",
      "0    16001\n",
      "1    15999\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_counts = data['clickbait'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap in headlines between train and test: 3\n"
     ]
    }
   ],
   "source": [
    "train_headlines = set(train_df['clean_headline'])\n",
    "test_headlines = set(test_df['clean_headline'])\n",
    "overlap = train_headlines.intersection(test_headlines)\n",
    "print(f\"Overlap in headlines between train and test: {len(overlap)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
